
train:
  dataset: 'cifar10'  #'mnist','cifar10','cifar100','tiny-imagenet','imagenet'
  model: 'resnet18' #'conv','fc1',
              # 'vgg11','vgg11-bn','vgg13','vgg13-bn','vgg16','vgg16-bn','vgg19','vgg19-bn',
              # 'resnet18','resnet20','resnet32','resnet34','resnet44','resnet50',
              # 'resnet56','resnet101','resnet110','resnet110','resnet152','resnet1202',
              # 'wide-resnet18','wide-resnet20','wide-resnet32','wide-resnet34','wide-resnet44','wide-resnet50',
              # 'wide-resnet56','wide-resnet101','wide-resnet110','wide-resnet110','wide-resnet152','wide-resnet1202'
  model_class: tinyimagenet #'default','lottery','tinyimagenet','imagenet'
  dense_classifier: False
  pretrained: False
  optimizer: 'adam' #'sgd','momentum','adam','rms'
  train_batchsize: 64
  test_batchsize: 256
  pre_epochs: 0
  post_epochs: 10
  lr: 0.001
  lr_drops: []
  lr_drop_rate: 0.1
  weight_decay: 0.0001

prune:
  pruner: autos #'rand','mag','snip','grasp','synflow','autos'
  compression: [0.8, 0.7, 0.5, 0.3, 0.1, 0.05, 0.01]
  schedule: pct #pct, num
  prune_epochs: 1
  mask_scope: 'global' #'global','local'
  prune_dataset_ratio: 10
  prune_batchsize: 256
  prune_bias: False
  prune_batchnorm: False
  prune_residual: False
  prune_train_mode: False
  reinitialize: False
  rewind: False
  shuffle: False
  invert: False
  pruner_list: []
  prune_epoch_list: []
  compression_list: []
  level_list: []

policy:
  experiment: prune #pretrain
  expid: 0
  result_dir: 'experiment/prune_resutls'
  gpu: 0
  workers: 4
  seed: 0
  verbose: False
  autos_model: 
  save_important: 
  run_choice: prune_autos #prune_iterative, prune_once, prune_autos
  times: 
  
  
